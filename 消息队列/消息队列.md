#### 为什么使用消息队列？消息队列有什么优点和缺点？
消息队列常见的使用场景吧，其实场景有很多，但是比较核心的有 3 个：解耦、异步、削峰。
缺点有以下几个：
系统可用性降低
系统引入的外部依赖越多，越容易挂掉。本来你就是 A 系统调用 BCD 三个系统的接口就好了，人 ABCD 四个系统好好的，没啥问题，你偏加个 MQ 进来，万一 MQ 挂了咋整，MQ 一挂，整套系统崩溃的，你不就完了？如何保证消息队列的高可用，可以点击这里查看。
系统复杂度提高
硬生生加个 MQ 进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已。
一致性问题
A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致了。


#### 引入消息队列之后该如何保证其高可用性？
##### RabbitMQ 的高可用性
````
基于主从（非分布式）做高可用性的.

RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。
````
RabbitMQ 普通集群模式 基本模式

https://www.processon.com/view/link/60447bf6e401fd4f9cbb8b8c

RabbitMQ 镜像集群模式 

https://www.processon.com/view/link/60448c17e401fd4f9cbbaa96

##### Kafka 的高可用性

https://www.processon.com/view/link/60476644e401fd4f9cc29daf

#### 如何保证消息不被重复消费？或者说，如何保证消息消费的幂等性？

kafka 每次每个消息写进去，都有一个 offset，代表消息的序号，然后 consumer 消费了数据之后，每隔一段时间（定时定期），会把自己消费过的消息的 offset 提交一下，表示“我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的 offset 来继续消费吧”。

保证幂等性 大多都是通过业务唯一键值来保证的。

#### 如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？

RabbitMQ：

RabbitMQ：通过 事物机制 或者 confirm 机制来保证数据传输。
事务机制是同步的，你提交一个事务之后会阻塞在那，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息；如果收到了消息，那么可以提交事务channel.txCommit。
confirm 机制是异步的，，在生产者那里设置开启 confirm 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会给你回传一个 ack 消息，告诉你说这个消息 ok 了。如果 RabbitMQ 没能处理这个消息，会回调你的一个 nack 接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

生产者消息丢失的问题：
RabbitMQ：开启持久化
设置持久化有两个步骤：
    1. 创建 queue 的时候将其设置为持久化,这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。
    2. 发送消息的时候将消息的 deliveryMode 设置为 2，就是将消息设置为持久化的，此时 RabbitMQ 就会将消息持久化到磁盘上去。

持久化可以跟生产者那边的 confirm 机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者 ack 了，所以哪怕是在持久化到磁盘之前，RabbitMQ 挂了，数据丢了，生产者收不到 ack，你也是可以自己重发的。

消费端消息丢失的问题：
    关闭 RabbitMQ 的自动 ack，可以通过一个 api 来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里 ack 一把。这样的话，如果你还没处理完，不就没有 ack 了？那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处理，消息是不会丢的。

Kafka：
Kafka本身是通过offset来保证数据传输的。消费端会告诉Kafka消费到哪了。

Kafka丢失数据问题解决：
    结合kafka高可用模型来说： https://www.processon.com/view/link/60476644e401fd4f9cc29daf
    1. 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
    2. leader必须跟至少一个副本保持连接。在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
    3. 在 producer （生产者） 端设置 acks=all：这个是要求每条数据，必须是写入所有 replica（副本） 之后，才能认为是写成功了。
    4. 在 producer （生产者） 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试
生产者消息丢失的问题： 
    设置了 acks=all，一定不会丢，要求是，你的 leader 接收到消息，所有的 follower 都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。    
消费端消息丢失的问题： 
    关闭自动提交 offset，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是可能会有重复消费，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。

#### 怎么设计一个消息中间件？

动态扩容，持久化方案，高可用，数据完整性。























#### Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么优点和缺点？

ActiveMQ:

    1. 单机吞吐量:  万级，比 RocketMQ、Kafka 低一个数量级
    2. topic 数量对吞吐量的影响:
    3. 时效性: ms 级
    4. 可用性: 高，基于主从架构实现高可用
    5. 消息可靠性: 有较低的概率丢失数据
    6. 功能支持: MQ 领域的功能极其完备

RabbitMQ:

    1. 单机吞吐量:  万级，比 RocketMQ、Kafka 低一个数量级
    2. topic 数量对吞吐量的影响:
    3. 时效性: 微秒级，这是 RabbitMQ 的一大特点，延迟最低
    4. 可用性: 高，基于主从架构实现高可用
    5. 消息可靠性: 基本不丢
    6. 功能支持: 基于 erlang 开发，并发能力很强，性能极好，延时很低

RocketMQ:

    1. 单机吞吐量:  10 万级，支撑高吞吐
    2. topic 数量对吞吐量的影响: topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic
    3. 时效性: ms 级
    4. 可用性: 非常高，分布式架构
    5. 消息可靠性: 经过参数优化配置，可以做到 0 丢失
    6. 功能支持: MQ 功能较为完善，还是分布式的，扩展性好	

Kafka:

    1. 单机吞吐量:  10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景
    2. topic 数量对吞吐量的影响: topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源
    3. 时效性: ms 级
    4. 可用性: 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用
    5. 消息可靠性: 同 RocketMQ
    6. 功能支持: 功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用


























